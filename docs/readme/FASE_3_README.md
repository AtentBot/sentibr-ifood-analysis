# üöÄ Fase 3 - API REST (FastAPI)

API REST completa e pronta para produ√ß√£o para an√°lise de sentimento usando modelo BERT fine-tuned.

---

## üìã Vis√£o Geral

A API foi desenvolvida com **FastAPI** e inclui:

‚úÖ **Endpoints Principais:**
- Single prediction
- Batch prediction
- Model information
- Health check

‚úÖ **Endpoints Avan√ßados (Diferenciais):**
- Model comparison (BERT vs GPT)
- Explainability (attention weights, LIME, SHAP)
- Human feedback collection
- Comprehensive metrics
- Prometheus integration

‚úÖ **Recursos de Produ√ß√£o:**
- Rate limiting
- Error handling
- Request logging
- CORS configurado
- Swagger UI customizado
- Async endpoints
- Metrics collection

---

## üèóÔ∏è Estrutura

```
src/api/
‚îú‚îÄ‚îÄ __init__.py          # M√≥dulo principal
‚îú‚îÄ‚îÄ main.py              # FastAPI application
‚îú‚îÄ‚îÄ models.py            # Pydantic models
‚îú‚îÄ‚îÄ inference.py         # Servi√ßo de infer√™ncia
‚îî‚îÄ‚îÄ middleware.py        # Logging, metrics, error handling

Arquivos auxiliares:
‚îú‚îÄ‚îÄ start_api.py         # Script de inicializa√ß√£o
‚îú‚îÄ‚îÄ test_api.py          # Suite de testes
‚îú‚îÄ‚îÄ .env.example         # Exemplo de configura√ß√£o
‚îî‚îÄ‚îÄ docs/API.md          # Documenta√ß√£o completa
```

---

## üöÄ Como Usar

### 1. Instala√ß√£o

```bash
# Instalar depend√™ncias
pip install -r requirements.txt
```

### 2. Configura√ß√£o (Opcional)

```bash
# Copiar arquivo de exemplo
cp .env.example .env

# Editar configura√ß√µes
nano .env
```

### 3. Iniciar a API

**Op√ß√£o 1: Script de inicializa√ß√£o (Recomendado)**
```bash
# Desenvolvimento (com hot reload)
python start_api.py --reload

# Produ√ß√£o
python start_api.py --workers 4
```

**Op√ß√£o 2: Uvicorn direto**
```bash
# Desenvolvimento
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Produ√ß√£o
uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### 4. Acessar a Documenta√ß√£o

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## üß™ Testar a API

### Testes Automatizados

```bash
# Executar suite completa de testes
python test_api.py
```

### Testes Manuais (cURL)

```bash
# Health check
curl http://localhost:8000/health

# Predi√ß√£o simples
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "Produto excelente!", "return_probabilities": true}'

# Predi√ß√£o em lote
curl -X POST http://localhost:8000/api/v1/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "texts": ["√ìtimo!", "P√©ssimo", "Normal"],
    "return_probabilities": false
  }'

# M√©tricas
curl http://localhost:8000/api/v1/metrics

# Informa√ß√µes do modelo
curl http://localhost:8000/api/v1/models/info
```

---

## üì° Endpoints Principais

### 1. `/health` - Health Check
```python
import requests

response = requests.get("http://localhost:8000/health")
print(response.json())
```

### 2. `/api/v1/predict` - Predi√ß√£o √önica
```python
import requests

payload = {
    "text": "Eu adorei o produto!",
    "return_probabilities": True
}

response = requests.post(
    "http://localhost:8000/api/v1/predict",
    json=payload
)

result = response.json()
print(f"Sentimento: {result['sentiment']}")
print(f"Confian√ßa: {result['score']:.2%}")
```

### 3. `/api/v1/predict/batch` - Predi√ß√£o em Lote
```python
import requests

payload = {
    "texts": [
        "Produto excelente!",
        "Muito ruim",
        "√â ok"
    ],
    "return_probabilities": False
}

response = requests.post(
    "http://localhost:8000/api/v1/predict/batch",
    json=payload
)

results = response.json()
for i, pred in enumerate(results['predictions']):
    print(f"{i+1}. {pred['sentiment']} ({pred['score']:.2%})")
```

### 4. `/api/v1/models/info` - Informa√ß√µes do Modelo
```python
import requests

response = requests.get("http://localhost:8000/api/v1/models/info")
info = response.json()

print(f"Modelo: {info['model_name']}")
print(f"Vers√£o: {info['model_version']}")
print(f"Par√¢metros: {info['num_parameters']:,}")
print(f"Classes: {info['classes']}")
```

---

## üåü Endpoints Avan√ßados (Diferenciais)

### 1. Compara√ß√£o de Modelos
```python
# Comparar BERT com GPT
response = requests.post(
    "http://localhost:8000/api/v1/predict/compare",
    json={
        "text": "O produto √© muito bom",
        "gpt_model": "gpt-3.5-turbo"
    }
)
```

### 2. Explicabilidade
```python
# Obter explica√ß√£o da predi√ß√£o
response = requests.post(
    "http://localhost:8000/api/v1/explain",
    json={
        "text": "Produto excelente!",
        "method": "attention"
    }
)

result = response.json()
print(f"Palavras importantes:")
for word, importance in result['explanation']['word_importance'].items():
    print(f"  {word}: {importance:.4f}")
```

### 3. Feedback Humano
```python
# Submeter feedback
response = requests.post(
    "http://localhost:8000/api/v1/feedback",
    json={
        "text": "O produto √© ok",
        "predicted_sentiment": "positive",
        "predicted_score": 0.65,
        "correct_sentiment": "neutral",
        "comments": "Deveria ser neutro"
    }
)
```

### 4. M√©tricas
```python
# Obter m√©tricas detalhadas
response = requests.get("http://localhost:8000/api/v1/metrics")
metrics = response.json()

print(f"Total de predi√ß√µes: {metrics['total_predictions']}")
print(f"Confian√ßa m√©dia: {metrics['average_confidence']:.2%}")
print(f"Lat√™ncia m√©dia: {metrics['average_latency_ms']:.2f}ms")
print(f"Taxa de erro: {metrics['error_rate']:.2%}")
```

---

## üìä Performance

### Lat√™ncia
- **CPU**: ~45ms por predi√ß√£o
- **GPU**: ~20ms por predi√ß√£o
- **Batch (10 textos)**: ~8ms por texto

### Throughput
- **Requisi√ß√µes individuais**: ~20-50 req/s
- **Batch processing**: ~120-280 textos/s

### Recursos
- **Mem√≥ria**: ~2GB
- **CPU**: 1-2 cores
- **GPU**: Opcional, 4GB+ VRAM

---

## üîí Seguran√ßa

### Rate Limiting
- **Limite padr√£o**: 100 requests/minuto por IP
- **Headers de resposta**:
  - `X-RateLimit-Limit`: Limite total
  - `X-RateLimit-Remaining`: Requests restantes
  - `X-RateLimit-Reset`: Timestamp de reset

### CORS
- Configurado para aceitar todas as origens (desenvolvimento)
- **Produ√ß√£o**: Especificar origens permitidas no `.env`

---

## üìà Monitoramento

### Prometheus
```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'sentiment-api'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/api/v1/metrics/prometheus'
```

### Logs
- Formato JSON estruturado
- Arquivo: `logs/api.log`
- Rota√ß√£o autom√°tica

### M√©tricas Dispon√≠veis
- Total de predi√ß√µes
- Predi√ß√µes por sentimento
- Confian√ßa m√©dia
- Lat√™ncia m√©dia
- Taxa de erro
- Uptime

---

## üê≥ Docker

```bash
# Build
docker build -t sentiment-api:latest .

# Run
docker run -d \
  -p 8000:8000 \
  -v $(pwd)/models:/models \
  sentiment-api:latest
```

---

## üß™ Testes

### Unit Tests
```bash
pytest tests/unit/test_api_endpoints.py -v
```

### Integration Tests
```bash
pytest tests/integration/test_api_workflow.py -v
```

### Load Tests
```bash
locust -f tests/load/locustfile.py
```

---

## üìö Documenta√ß√£o

- **API Completa**: [docs/API.md](docs/API.md)
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Fase 3 conclu√≠da** - API REST implementada
2. ‚è≠Ô∏è **Fase 4** - Frontend (Streamlit)
3. ‚è≠Ô∏è **Fase 5** - Observabilidade e Monitoring
4. ‚è≠Ô∏è **Fase 6** - MLOps e CI/CD

---

## üêõ Troubleshooting

### Problema: Model not found
```bash
# Treinar o modelo primeiro
python src/training/train.py
```

### Problema: Port already in use
```bash
# Usar porta diferente
python start_api.py --port 8001
```

### Problema: High memory usage
```bash
# Usar FP16 (half precision)
export USE_FP16=true
python start_api.py
```

---

## üí° Dicas

1. **Desenvolvimento**: Use `--reload` para hot reload
2. **Produ√ß√£o**: Use m√∫ltiplos workers (`--workers 4`)
3. **Performance**: Prefira batch predictions
4. **Monitoramento**: Configure Prometheus
5. **Feedback**: Colete feedback humano regularmente

---

## üìù Checklist

- [x] FastAPI app configurado
- [x] Modelos Pydantic criados
- [x] Inference service implementado
- [x] Endpoints principais
- [x] Endpoints avan√ßados (diferenciais)
- [x] Error handling
- [x] Rate limiting
- [x] Logging estruturado
- [x] M√©tricas
- [x] Documenta√ß√£o Swagger
- [x] Scripts de teste
- [x] Script de inicializa√ß√£o
- [x] Documenta√ß√£o completa

---

## ‚úÖ Status

**Fase 3: COMPLETA** ‚úÖ

A API est√° pronta para produ√ß√£o com todos os recursos necess√°rios e diferenciais implementados!
