# üîß Troubleshooting Guide - Phase 6

Guia r√°pido de solu√ß√µes para problemas comuns da Fase 6.

---

## üö® Problemas de Instala√ß√£o

### ‚ùå "No module named 'X'"

**Problema:** Pacote Python n√£o instalado

**Solu√ß√£o:**
```bash
# Instalar todos os requirements
pip install -r requirements_phase6.txt

# Ou instalar pacote espec√≠fico
pip install nome-do-pacote
```

**Pacotes essenciais:**
- torch
- transformers
- openai
- lime
- scikit-learn
- pandas
- numpy
- matplotlib
- seaborn
- tqdm

---

### ‚ùå "CUDA out of memory"

**Problema:** GPU sem mem√≥ria suficiente

**Solu√ß√µes:**

1. **Reduzir batch size:**
```python
# Em phase6_eval_suite.py, linha ~50
y_pred, y_proba = self.predict_batch(texts, batch_size=8)  # Era 16
```

2. **For√ßar CPU:**
```python
# Adicionar ao inicializar
evaluator = ModelEvaluator(model_path, device='cpu')
```

3. **Liberar mem√≥ria GPU:**
```bash
# Matar processos usando GPU
nvidia-smi
kill -9 <PID>
```

---

### ‚ùå "Could not load BERT model"

**Problema:** Modelo BERT n√£o encontrado ou corrompido

**Verifica√ß√µes:**
```bash
# Verifica se modelo existe
ls -la models/bert_finetuned/

# Deve ter:
# - config.json
# - pytorch_model.bin (ou model.safetensors)
# - tokenizer_config.json
```

**Solu√ß√£o:**
- Execute o treinamento (Fase 2) primeiro
- Ou baixe modelo pr√©-treinado do HuggingFace
- Verifique se o caminho est√° correto

---

## üîë Problemas com OpenAI API

### ‚ùå "OPENAI_API_KEY not found"

**Problema:** API key n√£o configurada

**Solu√ß√£o:**

**Linux/Mac:**
```bash
export OPENAI_API_KEY='sk-proj-...'
```

**Windows (PowerShell):**
```powershell
$env:OPENAI_API_KEY='sk-proj-...'
```

**Windows (CMD):**
```cmd
set OPENAI_API_KEY=sk-proj-...
```

**Persistente (arquivo .env):**
```bash
# Crie arquivo .env
echo "OPENAI_API_KEY=sk-proj-..." > .env

# Instale python-dotenv
pip install python-dotenv

# Use no c√≥digo
from dotenv import load_dotenv
load_dotenv()
```

---

### ‚ùå "RateLimitError: Rate limit exceeded"

**Problema:** Muitas requisi√ß√µes √† API OpenAI

**Solu√ß√µes:**

1. **Aumentar delay entre requests:**
```python
# Em phase6_llm_judge.py, linha ~150
time.sleep(0.5)  # Era 0.1
```

2. **Reduzir n√∫mero de samples:**
```bash
python run_phase6.py --llm-samples 50  # Ao inv√©s de 100
```

3. **Upgrade do plano OpenAI:**
- Tier 1: 500 RPM
- Tier 2: 5000 RPM
- https://platform.openai.com/account/limits

---

### ‚ùå "AuthenticationError: Invalid API key"

**Problema:** API key incorreta ou expirada

**Verifica√ß√µes:**
```bash
# Ver key configurada (primeiros 10 chars)
echo $OPENAI_API_KEY | cut -c1-10

# Testar key
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

**Solu√ß√µes:**
- Gere nova key em: https://platform.openai.com/api-keys
- Verifique se n√£o h√° espa√ßos extras
- Confirme que key come√ßa com "sk-"

---

### ‚ùå "OpenAI API error: Insufficient quota"

**Problema:** Sem cr√©ditos na conta OpenAI

**Solu√ß√£o:**
- Adicione cr√©ditos: https://platform.openai.com/account/billing
- Ou pule componentes LLM:
```bash
python run_phase6.py --skip-llm-judge --skip-comparison
```

---

## üìÅ Problemas com Arquivos

### ‚ùå "predictions_*.csv not found"

**Problema:** Arquivo de predi√ß√µes n√£o existe

**Solu√ß√£o:**
```bash
# Execute primeiro a avalia√ß√£o b√°sica
python phase6_eval_suite.py

# Ou execute Fase 6 completa
python run_phase6.py
```

---

### ‚ùå "Test data not found"

**Problema:** data/processed/test.csv n√£o existe

**Solu√ß√£o:**
- Execute prepara√ß√£o de dados (Fase 1)
- Ou crie test.csv manualmente com colunas: `text`, `label`

---

### ‚ùå "Permission denied" ao executar setup

**Problema:** Script setup sem permiss√£o de execu√ß√£o

**Solu√ß√£o:**
```bash
chmod +x setup_phase6.sh
./setup_phase6.sh
```

---

## üêõ Problemas de Execu√ß√£o

### ‚ùå "LIME explainer takes too long"

**Problema:** LIME muito lento

**Solu√ß√µes:**

1. **Reduzir num_samples:**
```python
explanation = explainer.explain_prediction(
    text="...",
    num_samples=500  # Era 1000
)
```

2. **Reduzir n√∫mero de explica√ß√µes:**
```bash
python run_phase6.py --explainability-samples 10  # Ao inv√©s de 20
```

---

### ‚ùå "JSON decode error" em LLM Judge

**Problema:** GPT retornou resposta n√£o-JSON

**Causa:** Temperatura muito alta ou modelo hallucinating

**Solu√ß√£o:**
```python
# Em phase6_llm_judge.py, ajustar temperatura
response = self.client.chat.completions.create(
    model=self.model,
    temperature=0.1,  # Era 0.3 - mais determin√≠stico
    ...
)
```

---

### ‚ùå "Comparison shows BERT worse than GPT"

**Problema:** BERT com accuracy menor que GPT (inesperado)

**Causas poss√≠veis:**
1. Modelo BERT n√£o foi treinado corretamente
2. Sample muito pequeno (estatisticamente n√£o significativo)
3. Test set com distribui√ß√£o diferente do treino

**Verifica√ß√µes:**
```bash
# 1. Verifica se modelo foi treinado
ls -la models/bert_finetuned/

# 2. Aumenta sample size
python run_phase6.py --comparison-samples 200

# 3. Verifica distribui√ß√£o do test set
import pandas as pd
df = pd.read_csv('data/processed/test.csv')
print(df['label'].value_counts())
```

---

## üìä Problemas de Visualiza√ß√£o

### ‚ùå "Matplotlib display error"

**Problema:** Plots n√£o aparecem

**Solu√ß√µes:**

**Sem display (servidor):**
```python
# Adicionar no in√≠cio do arquivo
import matplotlib
matplotlib.use('Agg')  # Backend sem display
```

**Com display:**
```python
import matplotlib.pyplot as plt
plt.show()  # For√ßa exibi√ß√£o
```

---

### ‚ùå "Figure too large to save"

**Problema:** Plot muito grande

**Solu√ß√£o:**
```python
# Reduzir DPI
plt.savefig(path, dpi=150)  # Era 300

# Ou reduzir tamanho
fig, ax = plt.subplots(figsize=(8, 6))  # Era (14, 10)
```

---

## üíæ Problemas de Mem√≥ria

### ‚ùå "MemoryError: Unable to allocate"

**Problema:** RAM insuficiente

**Solu√ß√µes:**

1. **Processar em batches menores:**
```python
# Reduzir batch_size
for i in range(0, len(texts), 8):  # Era 16
```

2. **Limpar mem√≥ria:**
```python
import gc
import torch

# Ap√≥s cada batch
gc.collect()
torch.cuda.empty_cache()
```

3. **Usar menos samples:**
```bash
python run_phase6.py \
    --llm-samples 50 \
    --comparison-samples 50 \
    --explainability-samples 10
```

---

## ‚ö° Problemas de Performance

### ‚ùå "Phase 6 takes too long"

**Problema:** Execu√ß√£o muito lenta

**Tempos esperados:**
- Eval Framework: 2-5 min (1000 samples)
- LLM Judge: 5-10 min (100 samples)
- BERT vs GPT: 5-10 min (100 samples)
- Explainability: 10-20 min (20 samples)

**Total esperado:** 20-45 min

**Otimiza√ß√µes:**

1. **Usar GPU:**
```python
# Verificar se est√° usando GPU
import torch
print(torch.cuda.is_available())
```

2. **Reduzir samples:**
```bash
python run_phase6.py \
    --llm-samples 50 \
    --comparison-samples 50 \
    --explainability-samples 10
```

3. **Pular etapas demoradas:**
```bash
python run_phase6.py \
    --skip-explainability  # Mais demorada
```

---

## üîç Debug Avan√ßado

### Ativar logs detalhados

```python
# Adicionar no in√≠cio do script
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Testar componente isolado

```bash
# Teste r√°pido
python test_phase6.py

# Teste individual
python -c "from phase6_eval_suite import ModelEvaluator; print('OK')"
```

### Ver stack trace completo

```bash
# Executar com verbose
python run_phase6.py 2>&1 | tee phase6_debug.log
```

---

## üÜò Problemas N√£o Resolvidos?

### Checklist de debug:

1. ‚úÖ Todos os pacotes instalados?
   ```bash
   pip list | grep -E "torch|transformers|openai|lime"
   ```

2. ‚úÖ Modelo BERT existe e est√° completo?
   ```bash
   ls -la models/bert_finetuned/
   ```

3. ‚úÖ Test data existe e est√° formatado?
   ```bash
   head -n 5 data/processed/test.csv
   ```

4. ‚úÖ OpenAI key v√°lida? (se usar LLM)
   ```bash
   echo $OPENAI_API_KEY | cut -c1-10
   ```

5. ‚úÖ Mem√≥ria suficiente?
   ```bash
   free -h  # Linux
   # Ou no Python:
   import psutil; print(f"RAM: {psutil.virtual_memory().percent}%")
   ```

6. ‚úÖ GPU dispon√≠vel? (opcional)
   ```bash
   nvidia-smi  # Se CUDA
   ```

### Ainda com problemas?

1. Execute teste completo:
   ```bash
   python test_phase6.py
   ```

2. Verifique logs em:
   ```bash
   tail -n 100 evaluation_results/phase6_summary.json
   ```

3. Tente execu√ß√£o m√≠nima:
   ```bash
   python run_phase6.py \
       --skip-llm-judge \
       --skip-comparison \
       --skip-explainability
   ```

4. Documente o erro:
   - Mensagem de erro completa
   - Arquivo/linha onde ocorreu
   - O que estava tentando fazer
   - Logs relevantes

---

## üìö Recursos Adicionais

- **README Principal:** `README_PHASE6.md`
- **Resumo Executivo:** `EXECUTIVE_SUMMARY_PHASE6.md`
- **Test Suite:** `test_phase6.py`
- **Setup Script:** `setup_phase6.sh`

---

## üí° Dicas Gerais

### Execu√ß√£o passo a passo
```bash
# 1. Teste b√°sico primeiro
python test_phase6.py

# 2. Eval framework isolado
python phase6_eval_suite.py

# 3. LLM judge (com key)
export OPENAI_API_KEY='...'
python phase6_llm_judge.py

# 4. Compara√ß√£o
python phase6_bert_vs_gpt.py

# 5. Explainability
python phase6_explainability.py

# 6. Tudo junto
python run_phase6.py
```

### Come√ßar simples
```bash
# Vers√£o r√°pida (5-10 min)
python run_phase6.py \
    --skip-llm-judge \
    --skip-comparison \
    --explainability-samples 5
```

### Aumentar gradualmente
```bash
# Vers√£o completa mas r√°pida (15-20 min)
python run_phase6.py \
    --llm-samples 50 \
    --comparison-samples 50 \
    --explainability-samples 10

# Vers√£o completa padr√£o (30-45 min)
python run_phase6.py \
    --llm-samples 100 \
    --comparison-samples 100 \
    --explainability-samples 20
```

---

**Lembre-se:** A maioria dos problemas vem de:
1. ‚ùå Depend√™ncias n√£o instaladas
2. ‚ùå Modelo BERT n√£o treinado
3. ‚ùå OpenAI key n√£o configurada
4. ‚ùå Mem√≥ria insuficiente

Execute `python test_phase6.py` para identificar o problema! üîç

---

*SentiBR - Phase 6 Troubleshooting Guide*
