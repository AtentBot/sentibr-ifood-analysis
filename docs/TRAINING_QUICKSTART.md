# ğŸš€ Guia de InÃ­cio RÃ¡pido - Treinamento do BERT

Este guia te levarÃ¡ do zero ao modelo treinado em poucos passos.

## â±ï¸ Tempo Estimado

- **Setup inicial**: 10-15 minutos
- **Teste rÃ¡pido**: 5 minutos
- **Treinamento completo**: 30-90 minutos (com GPU) ou 4-8 horas (CPU)

## ğŸ“‹ PrÃ©-requisitos

- Python 3.10 ou superior
- 8GB+ de RAM
- 5GB+ de espaÃ§o em disco
- (Opcional mas recomendado) GPU com CUDA

## ğŸ¯ Passo a Passo

### Passo 1: Setup do Ambiente

Execute o script de setup automÃ¡tico:

```bash
python scripts/setup_training.py
```

Este script irÃ¡:
- âœ… Verificar versÃ£o do Python
- âœ… Instalar todas as dependÃªncias
- âœ… Criar diretÃ³rios necessÃ¡rios
- âœ… Criar dados de teste
- âœ… (Opcional) Executar teste rÃ¡pido

**Tempo: ~10 minutos**

### Passo 2: Preparar os Dados

#### OpÃ§Ã£o A: Dados de Teste RÃ¡pidos (Recomendado para comeÃ§ar)

```bash
# Criar dataset sintÃ©tico pequeno (1000 reviews)
python src/data/quick_test_data.py

# Dividir em train/val/test
python src/data/split_dataset.py
```

**Tempo: ~1 minuto**

#### OpÃ§Ã£o B: Dataset Real B2W-Reviews01

```bash
# Baixar e processar dataset real (~130k reviews)
python src/data/load_data_v2.py

# Dividir em train/val/test
python src/data/split_dataset.py
```

**Tempo: ~5-10 minutos** (depende da conexÃ£o)

#### OpÃ§Ã£o C: Dataset SintÃ©tico iFood

```bash
# Requer OPENAI_API_KEY no .env
python src/data/generate_synthetic_data.py

# Dividir em train/val/test
python src/data/split_dataset.py
```

**Tempo: ~10-20 minutos** (depende da quantidade)

### Passo 3: Explorar os Dados (Opcional mas Recomendado)

```bash
jupyter notebook notebooks/01_eda.ipynb
```

Isso te ajudarÃ¡ a entender:
- DistribuiÃ§Ã£o de sentimentos
- Qualidade dos textos
- Balanceamento das classes
- CaracterÃ­sticas do dataset

**Tempo: ~15-30 minutos**

### Passo 4: Teste RÃ¡pido do Pipeline

Antes de treinar o modelo completo, teste se tudo funciona:

```bash
python src/training/quick_test.py --samples 100 --epochs 1
```

VocÃª deve ver:
```
âœ… Train Loss: ~1.0
âœ… Train Acc: ~0.5-0.7
âœ… Val Acc: ~0.5-0.7
âœ… TESTE CONCLUÃDO COM SUCESSO!
```

**Tempo: ~2-5 minutos**

### Passo 5: Configurar HiperparÃ¢metros (Opcional)

Edite o arquivo `.env` para ajustar:

```bash
# Modelo
MODEL_NAME=neuralmind/bert-base-portuguese-cased
MAX_LENGTH=512
NUM_LABELS=3

# Treinamento
LEARNING_RATE=2e-5
BATCH_SIZE=16
NUM_EPOCHS=3
WARMUP_STEPS=500

# MLflow
MLFLOW_TRACKING_URI=file:./mlruns
```

### Passo 6: Treinar o Modelo ğŸš€

```bash
python src/training/train.py
```

O que vai acontecer:
1. âœ… Carregar dados
2. âœ… Inicializar BERT
3. âœ… Treinar por N Ã©pocas
4. âœ… Validar apÃ³s cada Ã©poca
5. âœ… Salvar melhor modelo
6. âœ… Registrar no MLflow

**Output esperado:**
```
ğŸš€ INICIANDO TREINAMENTO
================================================
ğŸ“Š Ã‰poca 1/3
  Train Loss: 0.6543, Train Acc: 0.7234
  Val Loss: 0.5432, Val Acc: 0.7891
  âœ… Melhor modelo atÃ© agora!

ğŸ“Š Ã‰poca 2/3
  Train Loss: 0.4321, Train Acc: 0.8123
  Val Loss: 0.4567, Val Acc: 0.8234
  âœ… Melhor modelo atÃ© agora!

ğŸ“Š Ã‰poca 3/3
  Train Loss: 0.3456, Train Acc: 0.8567
  Val Loss: 0.4601, Val Acc: 0.8198
  âš ï¸  Patience: 1/3

âœ… TREINAMENTO CONCLUÃDO
Melhor Val Loss: 0.4567
Melhor Val Acc: 0.8234
ğŸ’¾ Modelo salvo em: models/bert_finetuned/
```

**Tempo:**
- Dataset pequeno (1k): ~5-10 minutos (GPU) / 30-60 minutos (CPU)
- Dataset mÃ©dio (10k): ~15-30 minutos (GPU) / 2-4 horas (CPU)
- Dataset grande (100k+): ~60-90 minutos (GPU) / 6-12 horas (CPU)

### Passo 7: Avaliar o Modelo

```bash
python src/training/evaluate.py
```

VocÃª verÃ¡:
- âœ… MÃ©tricas detalhadas (Accuracy, Precision, Recall, F1)
- âœ… Confusion Matrix
- âœ… AnÃ¡lise de erros
- âœ… Classification Report

**Output esperado:**
```
ğŸ“Š MÃ‰TRICAS DE AVALIAÃ‡ÃƒO
================================================
Accuracy:  0.8234
Precision: 0.8123
Recall:    0.8198
F1-Score:  0.8156

ğŸ“Š MÃ©tricas por Classe:
  Negativo:
    Precision: 0.7856
    Recall:    0.8123
    F1-Score:  0.7987

  Neutro:
    Precision: 0.7234
    Recall:    0.6987
    F1-Score:  0.7108

  Positivo:
    Precision: 0.8789
    Recall:    0.8912
    F1-Score:  0.8850
```

**Tempo: ~2-5 minutos**

### Passo 8: Visualizar Experimentos (Opcional)

```bash
mlflow ui
```

Acesse: http://localhost:5000

VocÃª verÃ¡:
- ğŸ“Š GrÃ¡ficos de loss e accuracy
- ğŸ”¢ Todos os hiperparÃ¢metros
- ğŸ“ Modelos salvos
- ğŸ”„ ComparaÃ§Ã£o entre runs

## ğŸ‰ Pronto!

Seu modelo estÃ¡ treinado e salvo em `models/bert_finetuned/`!

## ğŸ’¡ PrÃ³ximos Passos

1. **Teste o modelo interativamente:**
   ```bash
   python -c "from transformers import pipeline; nlp = pipeline('sentiment-analysis', model='models/bert_finetuned'); print(nlp('Adorei o produto!'))"
   ```

2. **Crie a API REST:**
   ```bash
   # VÃ¡ para a Fase 3
   python src/api/main.py
   ```

3. **Inicie o Frontend:**
   ```bash
   # VÃ¡ para a Fase 4
   streamlit run frontend/app.py
   ```

## ğŸ› Problemas Comuns

### Erro: CUDA out of memory

**SoluÃ§Ã£o:** Reduza o batch size no `.env`:
```bash
BATCH_SIZE=8  # ou atÃ© 4
```

### Erro: Dataset nÃ£o encontrado

**SoluÃ§Ã£o:** Execute os scripts de dados:
```bash
python src/data/quick_test_data.py
python src/data/split_dataset.py
```

### Modelo nÃ£o aprende (loss nÃ£o diminui)

**Verifique:**
- [ ] Learning rate (tente 3e-5 ou 1e-5)
- [ ] Dataset balanceado
- [ ] Labels corretos (0, 1, 2)
- [ ] Batch size adequado

### Erro: ModuleNotFoundError

**SoluÃ§Ã£o:** Reinstale dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ“Š Benchmarks

### Dataset de Teste (1k reviews)
- **Tempo de treinamento:** 5-10 min (GPU) / 30-60 min (CPU)
- **Accuracy esperada:** 80-85%
- **F1-Score esperado:** 0.75-0.80

### Dataset Real (130k reviews)
- **Tempo de treinamento:** 60-90 min (GPU) / 6-8 horas (CPU)
- **Accuracy esperada:** 85-90%
- **F1-Score esperado:** 0.82-0.88

## ğŸ“ Dicas AvanÃ§adas

### 1. Usar GPU no Google Colab

Se nÃ£o tem GPU local:

1. Abra [Google Colab](https://colab.research.google.com)
2. Runtime â†’ Change runtime type â†’ GPU
3. Clone o repositÃ³rio:
   ```python
   !git clone https://github.com/seu-usuario/sentibr-ifood-analysis
   %cd sentibr-ifood-analysis
   ```
4. Execute os scripts normalmente

### 2. Ajustar para seu dataset

Se usar seu prÃ³prio dataset, ajuste em `src/config.py`:
- `text_column`: nome da coluna com o texto
- `label_column`: nome da coluna com o label
- `num_labels`: nÃºmero de classes

### 3. Salvar checkpoints intermediÃ¡rios

Edite `src/training/train.py` e adicione:
```python
if epoch % 2 == 0:
    checkpoint_path = f"models/checkpoint_epoch_{epoch}"
    self.save_model(checkpoint_path)
```

### 4. Hyperparameter Tuning

Para encontrar os melhores hiperparÃ¢metros automaticamente:
```bash
# TODO: Adicionar script de tuning com Optuna
python src/training/hyperparameter_tuning.py
```

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o do Transformers](https://huggingface.co/docs/transformers/)
- [Fine-tuning BERT Tutorial](https://huggingface.co/docs/transformers/training)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [MLflow Tracking](https://www.mlflow.org/docs/latest/tracking.html)

## â“ Ainda com DÃºvidas?

1. Leia o [README principal](../README.md)
2. Consulte o [README do mÃ³dulo de treinamento](src/training/README.md)
3. Veja os [notebooks de exemplo](notebooks/)
4. Abra uma issue no GitHub

---

**Ãšltima atualizaÃ§Ã£o:** Novembro 2024
**VersÃ£o:** 1.0.0
