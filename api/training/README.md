# ğŸ“ MÃ³dulo de Treinamento - SentiBR

Este mÃ³dulo contÃ©m todos os scripts necessÃ¡rios para treinar o modelo BERT para anÃ¡lise de sentimento.

## ğŸ“ Estrutura

```
src/training/
â”œâ”€â”€ __init__.py           # MÃ³dulo Python
â”œâ”€â”€ dataset.py            # Dataset PyTorch customizado
â”œâ”€â”€ train.py              # Script principal de treinamento
â”œâ”€â”€ evaluate.py           # Script de avaliaÃ§Ã£o detalhada
â”œâ”€â”€ quick_test.py         # Teste rÃ¡pido do pipeline
â””â”€â”€ README.md             # Esta documentaÃ§Ã£o
```

## ğŸš€ Quick Start

### 1. Preparar os Dados

Antes de treinar, vocÃª precisa ter os dados preparados e divididos:

```bash
# OpÃ§Ã£o A: Carregar dados reais
python src/data/load_data_v2.py
python src/data/split_dataset.py

# OpÃ§Ã£o B: Criar dados de teste rÃ¡pidos
python src/data/quick_test_data.py
python src/data/split_dataset.py
```

### 2. Teste RÃ¡pido (Recomendado)

Antes de treinar o modelo completo, teste o pipeline:

```bash
python src/training/quick_test.py --samples 100 --epochs 1
```

Isso irÃ¡:
- âœ… Verificar se o ambiente estÃ¡ configurado corretamente
- âœ… Testar se o modelo carrega
- âœ… Executar 1 Ã©poca de treinamento em 100 samples
- âœ… Validar que tudo funciona

**Tempo estimado: 2-5 minutos**

### 3. Treinamento Completo

Quando o teste passar, execute o treinamento completo:

```bash
python src/training/train.py
```

**Tempo estimado:**
- CPU: 4-8 horas (dependendo do dataset)
- GPU: 30-90 minutos

### 4. AvaliaÃ§Ã£o Detalhada

ApÃ³s o treinamento, avalie o modelo:

```bash
python src/training/evaluate.py
```

Isso irÃ¡:
- Calcular todas as mÃ©tricas (accuracy, precision, recall, F1)
- Gerar confusion matrix
- Analisar os erros do modelo
- Salvar relatÃ³rio completo

## ğŸ“Š Arquivos Gerados

ApÃ³s o treinamento, vocÃª terÃ¡:

```
models/bert_finetuned/
â”œâ”€â”€ config.json               # ConfiguraÃ§Ã£o do modelo
â”œâ”€â”€ pytorch_model.bin         # Pesos do modelo
â”œâ”€â”€ tokenizer_config.json     # ConfiguraÃ§Ã£o do tokenizer
â”œâ”€â”€ vocab.txt                 # VocabulÃ¡rio
â”œâ”€â”€ metrics.json              # MÃ©tricas de validaÃ§Ã£o
â””â”€â”€ training_config.json      # HiperparÃ¢metros usados

mlruns/                       # Experimentos MLflow
â””â”€â”€ 0/
    â””â”€â”€ <run_id>/
        â”œâ”€â”€ metrics/          # MÃ©tricas por Ã©poca
        â”œâ”€â”€ params/           # HiperparÃ¢metros
        â””â”€â”€ artifacts/        # Artefatos salvos

logs/
â”œâ”€â”€ confusion_matrix.png      # Matriz de confusÃ£o
â””â”€â”€ evaluation_report.json    # RelatÃ³rio completo
```

## âš™ï¸ ConfiguraÃ§Ã£o

As configuraÃ§Ãµes de treinamento estÃ£o em `src/config.py`:

```python
# Modelo
MODEL_NAME = "neuralmind/bert-base-portuguese-cased"
NUM_LABELS = 3  # positivo, neutro, negativo
MAX_LENGTH = 512

# Treinamento
LEARNING_RATE = 2e-5
BATCH_SIZE = 16
NUM_EPOCHS = 3
WARMUP_STEPS = 500
WEIGHT_DECAY = 0.01

# Early Stopping
PATIENCE = 3  # Parar apÃ³s 3 Ã©pocas sem melhora
```

VocÃª pode ajustar essas configuraÃ§Ãµes no arquivo `.env` ou diretamente no `config.py`.

## ğŸ”§ HiperparÃ¢metros Recomendados

### Para datasets pequenos (< 10k samples):
```python
LEARNING_RATE = 3e-5
BATCH_SIZE = 16
NUM_EPOCHS = 5
```

### Para datasets mÃ©dios (10k-100k samples):
```python
LEARNING_RATE = 2e-5
BATCH_SIZE = 32
NUM_EPOCHS = 3
```

### Para datasets grandes (> 100k samples):
```python
LEARNING_RATE = 2e-5
BATCH_SIZE = 64
NUM_EPOCHS = 2
```

## ğŸ› Troubleshooting

### Erro: CUDA out of memory

**SoluÃ§Ã£o 1: Reduzir batch size**
```bash
# No .env
BATCH_SIZE=8
```

**SoluÃ§Ã£o 2: Reduzir max_length**
```bash
# No .env
MAX_LENGTH=256
```

**SoluÃ§Ã£o 3: Usar gradient accumulation** (adicionar no cÃ³digo se necessÃ¡rio)

### Erro: Dataset nÃ£o encontrado

```bash
# Execute primeiro:
python src/data/quick_test_data.py
python src/data/split_dataset.py
```

### Erro: MLflow tracking URI

```bash
# No .env
MLFLOW_TRACKING_URI=file:./mlruns
```

### Modelo nÃ£o aprende (loss nÃ£o diminui)

Verifique:
- [ ] Learning rate muito baixo? Tente 3e-5
- [ ] Learning rate muito alto? Tente 1e-5
- [ ] Dataset balanceado? Use class weights se necessÃ¡rio
- [ ] Labels corretos? Verifique no EDA

## ğŸ“ˆ Monitoramento com MLflow

Visualize os experimentos:

```bash
mlflow ui
```

Acesse: http://localhost:5000

VocÃª verÃ¡:
- ğŸ“Š GrÃ¡ficos de loss e accuracy por Ã©poca
- ğŸ”¢ Todos os hiperparÃ¢metros usados
- ğŸ“ Modelos e artefatos salvos
- ğŸ”„ ComparaÃ§Ã£o entre diferentes runs

## ğŸ¯ MÃ©tricas de Sucesso

Um bom modelo deve ter:

- âœ… **Accuracy > 0.80** (80%)
- âœ… **F1-Score > 0.75** por classe
- âœ… **Precision e Recall balanceados** (diferenÃ§a < 0.1)
- âœ… **Confusion matrix** sem confusÃµes extremas

Se as mÃ©tricas estiverem abaixo:
1. Verifique a qualidade dos dados (EDA)
2. Tente diferentes hiperparÃ¢metros
3. Aumente o tamanho do dataset
4. Considere data augmentation
5. Experimente diferentes modelos base

## ğŸš€ PrÃ³ximos Passos

ApÃ³s treinar o modelo com sucesso:

1. âœ… Avaliar detalhadamente (`evaluate.py`)
2. âœ… Criar API REST (Fase 3)
3. âœ… Integrar com frontend (Fase 4)
4. âœ… Configurar monitoring (Fase 5)

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o do Transformers](https://huggingface.co/docs/transformers/)
- [Fine-tuning BERT](https://huggingface.co/docs/transformers/training)
- [MLflow Tracking](https://www.mlflow.org/docs/latest/tracking.html)
- [PyTorch Lightning](https://pytorch-lightning.readthedocs.io/) (alternativa avanÃ§ada)

## ğŸ’¡ Dicas AvanÃ§adas

### 1. Usar GPU na Colab

```python
# No Colab, sempre use GPU:
# Runtime > Change runtime type > GPU

# Verificar:
import torch
print(torch.cuda.is_available())  # Deve ser True
```

### 2. Salvar checkpoints intermediÃ¡rios

```python
# Adicionar no train.py:
if epoch % 2 == 0:  # A cada 2 Ã©pocas
    checkpoint_path = f"models/checkpoint_epoch_{epoch}"
    trainer.save_model(checkpoint_path)
```

### 3. Usar Learning Rate Finder

```python
# Experimentar diferentes LRs automaticamente
from torch.optim.lr_scheduler import ReduceLROnPlateau

scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=1)
```

### 4. Data Augmentation

```python
# Adicionar augmentation no dataset.py
import nlpaug.augmenter.word as naw

aug = naw.SynonymAug(aug_src='wordnet')
augmented_text = aug.augment(text)
```

## ğŸ¤ Contribuindo

Para adicionar novas features ao mÃ³dulo de treinamento:

1. Adicione testes unitÃ¡rios
2. Documente no README
3. Atualize o `requirements.txt` se necessÃ¡rio
4. Teste com `quick_test.py`

## ğŸ“§ Suporte

Problemas? Abra uma issue no GitHub com:
- Logs completos do erro
- ConfiguraÃ§Ãµes usadas (.env)
- InformaÃ§Ãµes do sistema (GPU, RAM, etc)
