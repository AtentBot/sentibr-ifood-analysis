"""
SentiBR - Monitoramento
Status e saÃºde do sistema em tempo real
"""
import streamlit as st
import requests
import time
from datetime import datetime

st.set_page_config(page_title="Monitoramento", page_icon="ğŸ“ˆ", layout="wide")

st.title("ğŸ“ˆ Monitoramento do Sistema")
st.markdown("Status e saÃºde de todos os serviÃ§os")

# FunÃ§Ã£o para verificar saÃºde
def check_health(url, timeout=2):
    try:
        response = requests.get(url, timeout=timeout)
        return response.status_code == 200
    except:
        return False

# Status geral
st.subheader("ğŸ¯ Status Geral")

col1, col2, col3, col4 = st.columns(4)

with col1:
    api_status = check_health("http://api:8000/api/v1/health")
    if api_status:
        st.success("ğŸŸ¢ API Online")
    else:
        st.error("ğŸ”´ API Offline")

with col2:
    # Simular status do modelo
    st.success("ğŸŸ¢ Modelo BERT")

with col3:
    # Simular status do cache
    st.success("ğŸŸ¢ Redis Cache")

with col4:
    # Simular status do banco
    st.success("ğŸŸ¢ PostgreSQL")

# Detalhes dos serviÃ§os
st.markdown("---")
st.subheader("ğŸ”§ Detalhes dos ServiÃ§os")

# Criar tabs para cada serviÃ§o
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸŒ API",
    "ğŸ§  BERT Model",
    "ğŸ’¾ Redis",
    "ğŸ—„ï¸ PostgreSQL",
    "ğŸ“Š Observabilidade"
])

with tab1:
    st.markdown("### API FastAPI")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Status", "ğŸŸ¢ Online")
        st.metric("Uptime", "99.8%")
    
    with col2:
        st.metric("Requests/s", "147")
        st.metric("LatÃªncia P95", "123ms")
    
    with col3:
        st.metric("Erros", "0.2%")
        st.metric("Ãšltima verificaÃ§Ã£o", "5s atrÃ¡s")
    
    st.markdown("#### Endpoints")
    
    endpoints = [
        {"Endpoint": "/api/v1/health", "Status": "ğŸŸ¢", "LatÃªncia": "12ms"},
        {"Endpoint": "/api/v1/predict", "Status": "ğŸŸ¢", "LatÃªncia": "87ms"},
        {"Endpoint": "/api/v1/predict/batch", "Status": "ğŸŸ¢", "LatÃªncia": "234ms"},
        {"Endpoint": "/api/v1/model/info", "Status": "ğŸŸ¢", "LatÃªncia": "8ms"},
    ]
    
    import pandas as pd
    st.dataframe(pd.DataFrame(endpoints), hide_index=True, use_container_width=True)
    
    st.markdown("#### Logs Recentes")
    st.code("""
[2025-11-06 18:30:15] INFO - Request processed successfully
[2025-11-06 18:30:12] INFO - Model prediction: positive (0.92)
[2025-11-06 18:30:10] INFO - Health check passed
[2025-11-06 18:30:05] INFO - Cache hit: review_12345
[2025-11-06 18:30:01] INFO - New request received
""")

with tab2:
    st.markdown("### Modelo BERT")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Status", "ğŸŸ¢ Carregado")
        st.metric("VersÃ£o", "v1.2.3")
    
    with col2:
        st.metric("AcurÃ¡cia", "92.3%")
        st.metric("PrediÃ§Ãµes Hoje", "12,456")
    
    with col3:
        st.metric("MemÃ³ria", "1.8 GB")
        st.metric("LatÃªncia MÃ©dia", "87ms")
    
    st.markdown("#### InformaÃ§Ãµes do Modelo")
    st.json({
        "model_name": "neuralmind/bert-base-portuguese-cased",
        "num_labels": 3,
        "labels": ["negative", "neutral", "positive"],
        "max_length": 512,
        "trained_on": "150K reviews",
        "last_updated": "2025-11-01",
        "framework": "PyTorch 2.1.2"
    })
    
    st.markdown("#### Performance")
    st.progress(0.92, text="AcurÃ¡cia: 92%")
    st.progress(0.91, text="F1-Score: 91%")
    st.progress(0.89, text="Cache Hit Rate: 89%")

with tab3:
    st.markdown("### Redis Cache")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Status", "ğŸŸ¢ Conectado")
        st.metric("ConexÃµes", "42")
    
    with col2:
        st.metric("Hit Rate", "87.3%")
        st.metric("Keys", "1,234")
    
    with col3:
        st.metric("MemÃ³ria", "234 MB")
        st.metric("Evictions", "0")
    
    st.markdown("#### ConfiguraÃ§Ã£o")
    st.code("""
Host: redis
Port: 6379
Database: 0
Max Connections: 100
Timeout: 5s
TTL: 3600s (1 hora)
""")
    
    st.markdown("#### Top Keys")
    keys_df = pd.DataFrame({
        'Key': ['review:hash:abc123', 'review:hash:def456', 'review:hash:ghi789'],
        'TTL': ['45m', '32m', '18m'],
        'Tamanho': ['2.1 KB', '1.8 KB', '2.3 KB']
    })
    st.dataframe(keys_df, hide_index=True, use_container_width=True)

with tab4:
    st.markdown("### PostgreSQL")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Status", "ğŸŸ¢ Conectado")
        st.metric("ConexÃµes", "15/100")
    
    with col2:
        st.metric("Registros", "150,234")
        st.metric("Tamanho DB", "2.3 GB")
    
    with col3:
        st.metric("Queries/s", "23")
        st.metric("Cache Hit", "94%")
    
    st.markdown("#### Tabelas")
    tables_df = pd.DataFrame({
        'Tabela': ['reviews', 'predictions', 'feedbacks', 'model_versions'],
        'Registros': ['150,234', '152,891', '1,234', '12'],
        'Tamanho': ['1.8 GB', '450 MB', '12 MB', '2 MB']
    })
    st.dataframe(tables_df, hide_index=True, use_container_width=True)
    
    st.markdown("#### Queries Lentas")
    st.code("""
-- Nenhuma query lenta detectada nas Ãºltimas 24h
-- Todas as queries < 100ms
""")

with tab5:
    st.markdown("### Observabilidade")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### Prometheus")
        st.metric("Status", "ğŸŸ¢ Coletando")
        st.metric("MÃ©tricas", "87")
        st.metric("Targets", "5/5 UP")
        
        st.markdown("**Acesso:**")
        st.code("http://localhost:9090")
        
    with col2:
        st.markdown("#### Grafana")
        st.metric("Status", "ğŸŸ¢ Online")
        st.metric("Dashboards", "3")
        st.metric("PainÃ©is", "24")
        
        st.markdown("**Acesso:**")
        st.code("http://localhost:3000")
        st.caption("UsuÃ¡rio: admin | Senha: sentibr_grafana_2024")
    
    st.markdown("#### MLflow")
    st.metric("Status", "ğŸŸ¢ Online")
    st.metric("Experimentos", "15")
    st.metric("Modelos", "8")
    
    st.markdown("**Acesso:**")
    st.code("http://localhost:5000")

# Alertas
st.markdown("---")
st.subheader("âš ï¸ Alertas e NotificaÃ§Ãµes")

# Verificar se hÃ¡ alertas
has_alerts = False

if has_alerts:
    st.error("ğŸ”´ 2 alertas crÃ­ticos")
    st.warning("ğŸŸ¡ 5 avisos")
else:
    st.success("âœ… Sem alertas no momento")

# Ãšltimas notificaÃ§Ãµes
with st.expander("ğŸ“‹ Ãšltimas NotificaÃ§Ãµes"):
    notifications = [
        {"Hora": "18:25", "Tipo": "â„¹ï¸ Info", "Mensagem": "Backup automÃ¡tico concluÃ­do"},
        {"Hora": "15:30", "Tipo": "âœ… Success", "Mensagem": "Modelo atualizado para v1.2.3"},
        {"Hora": "12:45", "Tipo": "âš ï¸ Warning", "Mensagem": "LatÃªncia elevada detectada (resolvido)"},
        {"Hora": "09:15", "Tipo": "â„¹ï¸ Info", "Mensagem": "Limpeza de cache executada"},
        {"Hora": "06:00", "Tipo": "â„¹ï¸ Info", "Mensagem": "Health check noturno - OK"}
    ]
    
    st.dataframe(pd.DataFrame(notifications), hide_index=True, use_container_width=True)

# MÃ©tricas de Performance
st.markdown("---")
st.subheader("ğŸ“Š MÃ©tricas de Performance")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown("#### CPU")
    st.progress(0.45, text="45% (API)")
    st.progress(0.32, text="32% (DB)")
    st.progress(0.18, text="18% (Cache)")

with col2:
    st.markdown("#### MemÃ³ria")
    st.progress(0.67, text="67% (API)")
    st.progress(0.42, text="42% (DB)")
    st.progress(0.23, text="23% (Cache)")

with col3:
    st.markdown("#### Disco")
    st.progress(0.34, text="34% (Usado)")
    st.metric("DisponÃ­vel", "12.3 GB")

with col4:
    st.markdown("#### Rede")
    st.metric("In", "2.3 MB/s")
    st.metric("Out", "4.1 MB/s")

# AÃ§Ãµes rÃ¡pidas
st.markdown("---")
st.subheader("âš¡ AÃ§Ãµes RÃ¡pidas")

col1, col2, col3, col4 = st.columns(4)

with col1:
    if st.button("ğŸ”„ Atualizar Status", use_container_width=True):
        st.rerun()

with col2:
    if st.button("ğŸ§¹ Limpar Cache", use_container_width=True):
        with st.spinner("Limpando cache..."):
            time.sleep(1)
        st.success("Cache limpo!")

with col3:
    if st.button("ğŸ“Š Ver Grafana", use_container_width=True):
        st.markdown("[Abrir Grafana](http://localhost:3000)")

with col4:
    if st.button("ğŸ“ˆ Ver Prometheus", use_container_width=True):
        st.markdown("[Abrir Prometheus](http://localhost:9090)")

# InformaÃ§Ãµes do sistema
with st.expander("ğŸ’» InformaÃ§Ãµes do Sistema"):
    st.markdown(f"""
    **Timestamp**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    
    **Containers em ExecuÃ§Ã£o**: 8
    - sentibr-api
    - sentibr-frontend
    - sentibr-postgres
    - sentibr-redis
    - sentibr-prometheus
    - sentibr-grafana
    - sentibr-mlflow
    - sentibr-nginx
    
    **VersÃµes**:
    - API: v1.0.0
    - Frontend: v1.0.0
    - BERT Model: v1.2.3
    
    **Ambiente**: Production
    **Deploy**: Docker Compose
    **Host**: localhost
    """)

# Footer
st.markdown("---")
st.caption("ğŸ”„ Atualizado automaticamente a cada 30 segundos")

# Auto-refresh (opcional)
auto_refresh = st.checkbox("Auto-refresh", value=False)
if auto_refresh:
    time.sleep(30)
    st.rerun()
