"""
SentiBR - Phase 6 Quick Test
Testa rapidamente todos os componentes antes da execuÃ§Ã£o completa
"""

import sys
from pathlib import Path


def print_header(text):
    """Imprime cabeÃ§alho formatado"""
    print("\n" + "="*70)
    print(f"  {text}")
    print("="*70)


def test_imports():
    """Testa se todos os imports necessÃ¡rios funcionam"""
    print_header("ğŸ” TESTANDO IMPORTS")
    
    packages = {
        'torch': 'PyTorch',
        'transformers': 'Transformers',
        'openai': 'OpenAI',
        'lime.lime_text': 'LIME',
        'sklearn': 'Scikit-learn',
        'pandas': 'Pandas',
        'numpy': 'NumPy',
        'matplotlib': 'Matplotlib',
        'seaborn': 'Seaborn',
        'tqdm': 'TQDM'
    }
    
    failed = []
    
    for module, name in packages.items():
        try:
            __import__(module)
            print(f"  âœ… {name}")
        except ImportError as e:
            print(f"  âŒ {name}: {e}")
            failed.append(name)
    
    if failed:
        print(f"\nâš ï¸  Pacotes faltando: {', '.join(failed)}")
        print("Execute: pip install -r requirements_phase6.txt")
        return False
    
    print("\nâœ… Todos os imports funcionaram!")
    return True


def test_files():
    """Verifica se arquivos necessÃ¡rios existem"""
    print_header("ğŸ“ VERIFICANDO ARQUIVOS")
    
    required_files = [
        'phase6_eval_suite.py',
        'phase6_llm_judge.py',
        'phase6_bert_vs_gpt.py',
        'phase6_explainability.py',
        'run_phase6.py'
    ]
    
    missing = []
    
    for file in required_files:
        if Path(file).exists():
            size = Path(file).stat().st_size
            print(f"  âœ… {file} ({size:,} bytes)")
        else:
            print(f"  âŒ {file} - NÃƒO ENCONTRADO")
            missing.append(file)
    
    if missing:
        print(f"\nâš ï¸  Arquivos faltando: {', '.join(missing)}")
        return False
    
    print("\nâœ… Todos os arquivos encontrados!")
    return True


def test_phase6_modules():
    """Testa se os mÃ³dulos Phase 6 podem ser importados"""
    print_header("ğŸ TESTANDO MÃ“DULOS PHASE 6")
    
    modules = [
        ('phase6_eval_suite', 'ModelEvaluator'),
        ('phase6_llm_judge', 'LLMJudge'),
        ('phase6_bert_vs_gpt', 'BERTvsGPTComparison'),
        ('phase6_explainability', 'SentimentExplainer')
    ]
    
    failed = []
    
    for module_name, class_name in modules:
        try:
            module = __import__(module_name)
            cls = getattr(module, class_name)
            print(f"  âœ… {module_name}.{class_name}")
        except Exception as e:
            print(f"  âŒ {module_name}.{class_name}: {e}")
            failed.append(module_name)
    
    if failed:
        print(f"\nâš ï¸  MÃ³dulos com problema: {', '.join(failed)}")
        return False
    
    print("\nâœ… Todos os mÃ³dulos funcionais!")
    return True


def test_model_and_data():
    """Verifica se modelo e dados existem"""
    print_header("ğŸ¤– VERIFICANDO MODELO E DADOS")
    
    model_path = Path('models/bert_finetuned')
    test_data_path = Path('data/processed/test.csv')
    
    model_ok = False
    data_ok = False
    
    # Verifica modelo
    if model_path.exists():
        config_file = model_path / 'config.json'
        model_file = list(model_path.glob('*.bin')) or list(model_path.glob('*.safetensors'))
        
        if config_file.exists() and model_file:
            print(f"  âœ… Modelo BERT encontrado em {model_path}")
            model_ok = True
        else:
            print(f"  âš ï¸  DiretÃ³rio do modelo existe mas arquivos incompletos")
    else:
        print(f"  âŒ Modelo nÃ£o encontrado em {model_path}")
        print(f"     Execute o treinamento (Fase 2) primeiro")
    
    # Verifica dados
    if test_data_path.exists():
        try:
            import pandas as pd
            df = pd.read_csv(test_data_path, nrows=5)
            required_cols = ['text', 'label']
            
            if all(col in df.columns for col in required_cols):
                print(f"  âœ… Test data encontrado ({test_data_path})")
                data_ok = True
            else:
                print(f"  âš ï¸  Test data sem colunas necessÃ¡rias: {required_cols}")
        except Exception as e:
            print(f"  âš ï¸  Erro ao ler test data: {e}")
    else:
        print(f"  âŒ Test data nÃ£o encontrado em {test_data_path}")
        print(f"     Execute a preparaÃ§Ã£o de dados (Fase 1) primeiro")
    
    if model_ok and data_ok:
        print("\nâœ… Modelo e dados prontos!")
        return True
    else:
        print("\nâš ï¸  Complete as fases anteriores antes de rodar Fase 6")
        return False


def test_openai_key():
    """Verifica OpenAI API key"""
    print_header("ğŸ”‘ VERIFICANDO OPENAI API KEY")
    
    import os
    
    key = os.getenv('OPENAI_API_KEY')
    
    if key:
        key_preview = key[:10] + '...' + key[-4:] if len(key) > 14 else key[:10] + '...'
        print(f"  âœ… OPENAI_API_KEY encontrada ({key_preview})")
        
        # Tenta importar OpenAI
        try:
            from openai import OpenAI
            client = OpenAI(api_key=key)
            print(f"  âœ… OpenAI client inicializado")
            return True
        except Exception as e:
            print(f"  âš ï¸  Erro ao inicializar OpenAI client: {e}")
            print(f"     Verifique se a key estÃ¡ correta")
            return False
    else:
        print(f"  âš ï¸  OPENAI_API_KEY nÃ£o encontrada")
        print(f"\n     Para usar LLM-as-Judge e comparaÃ§Ã£o BERT vs GPT:")
        print(f"     export OPENAI_API_KEY='sua-key-aqui'")
        print(f"\n     Ou pule essas etapas com:")
        print(f"     python run_phase6.py --skip-llm-judge --skip-comparison")
        return False


def test_quick_prediction():
    """Testa uma prediÃ§Ã£o rÃ¡pida com BERT"""
    print_header("ğŸ”® TESTE RÃPIDO DE PREDIÃ‡ÃƒO")
    
    try:
        import torch
        from transformers import BertTokenizer, BertForSequenceClassification
        
        model_path = 'models/bert_finetuned'
        
        if not Path(model_path).exists():
            print("  â­ï¸  Pulando (modelo nÃ£o encontrado)")
            return True
        
        print("  ğŸ“¦ Carregando modelo...")
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')
        model = BertForSequenceClassification.from_pretrained(model_path)
        model.to(device)
        model.eval()
        
        print(f"  âœ… Modelo carregado no {device}")
        
        # PrediÃ§Ã£o de teste
        test_text = "A comida estava deliciosa!"
        
        print(f"\n  ğŸ§ª Testando prediÃ§Ã£o...")
        print(f"     Texto: '{test_text}'")
        
        with torch.no_grad():
            encodings = tokenizer(
                test_text,
                padding=True,
                truncation=True,
                max_length=128,
                return_tensors='pt'
            )
            
            input_ids = encodings['input_ids'].to(device)
            attention_mask = encodings['attention_mask'].to(device)
            
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()[0]
            pred = outputs.logits.argmax(dim=-1).cpu().numpy()[0]
        
        labels = {0: 'negativo', 1: 'neutro', 2: 'positivo'}
        
        print(f"\n  ğŸ¯ Resultado:")
        print(f"     PrediÃ§Ã£o: {labels[pred]}")
        print(f"     ConfianÃ§a: {probs[pred]:.2%}")
        print(f"     Probabilidades: neg={probs[0]:.2%}, neu={probs[1]:.2%}, pos={probs[2]:.2%}")
        
        print("\n  âœ… PrediÃ§Ã£o funcionando!")
        return True
        
    except Exception as e:
        print(f"  âŒ Erro na prediÃ§Ã£o: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_all_tests():
    """Executa todos os testes"""
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                              â•‘")
    print("â•‘          ğŸ§ª SentiBR - Phase 6 Quick Test Suite ğŸ§ª           â•‘")
    print("â•‘                                                              â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    
    results = {
        'Imports': test_imports(),
        'Arquivos': test_files(),
        'MÃ³dulos Phase 6': test_phase6_modules(),
        'Modelo e Dados': test_model_and_data(),
        'OpenAI Key': test_openai_key(),
        'PrediÃ§Ã£o BERT': test_quick_prediction()
    }
    
    # SumÃ¡rio
    print_header("ğŸ“‹ SUMÃRIO DOS TESTES")
    
    all_passed = True
    warnings = []
    failures = []
    
    for test_name, passed in results.items():
        if passed:
            print(f"  âœ… {test_name}")
        else:
            print(f"  âš ï¸  {test_name}")
            if test_name in ['OpenAI Key']:
                warnings.append(test_name)
            else:
                failures.append(test_name)
                all_passed = False
    
    print("\n" + "="*70)
    
    if all_passed:
        print("\nğŸ‰ TODOS OS TESTES CRÃTICOS PASSARAM!")
        print("\nğŸš€ Sistema pronto para Fase 6!")
        
        if warnings:
            print(f"\nâš ï¸  Avisos (componentes opcionais):")
            for warning in warnings:
                print(f"   â€¢ {warning}")
            print("\n   VocÃª pode rodar Fase 6 pulando esses componentes:")
            print("   python run_phase6.py --skip-llm-judge --skip-comparison")
        
        print("\nğŸ“Œ PrÃ³ximos passos:")
        print("   1. Execute: python run_phase6.py")
        print("   2. Ou componentes individuais:")
        print("      â€¢ python phase6_eval_suite.py")
        print("      â€¢ python phase6_llm_judge.py")
        print("      â€¢ python phase6_bert_vs_gpt.py")
        print("      â€¢ python phase6_explainability.py")
        
        return 0
    else:
        print("\nâŒ ALGUNS TESTES FALHARAM")
        print(f"\n   Problemas encontrados:")
        for failure in failures:
            print(f"   â€¢ {failure}")
        
        print("\n   Corrija os problemas acima antes de rodar Fase 6")
        print("   Consulte README_PHASE6.md para mais informaÃ§Ãµes")
        
        return 1


if __name__ == '__main__':
    exit_code = run_all_tests()
    sys.exit(exit_code)
