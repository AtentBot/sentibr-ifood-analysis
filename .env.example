# Sentiment Analysis API - Environment Configuration

# =============================================================================
# API CONFIGURATION
# =============================================================================

# API Server
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
API_RELOAD=true

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Model paths
MODEL_PATH=/home/claude/models/bert_finetuned
MODEL_VERSION=v1.0

# Device configuration
DEVICE=cuda  # Options: cuda, cpu, auto
USE_FP16=false  # Use half precision (faster, less memory)

# =============================================================================
# RATE LIMITING
# =============================================================================

# Rate limit settings
RATE_LIMIT_ENABLED=true
RATE_LIMIT_CALLS=100
RATE_LIMIT_PERIOD=60  # seconds

# Batch limits
MAX_BATCH_SIZE=100
BATCH_TIMEOUT=30  # seconds

# =============================================================================
# LOGGING
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
LOG_FORMAT=json  # Options: json, text
LOG_FILE=logs/api.log
LOG_MAX_SIZE=10485760  # 10MB
LOG_BACKUP_COUNT=5

# =============================================================================
# MONITORING
# =============================================================================

# Prometheus metrics
PROMETHEUS_ENABLED=true
METRICS_PATH=/api/v1/metrics/prometheus

# Health check
HEALTH_CHECK_ENABLED=true

# =============================================================================
# SECURITY
# =============================================================================

# CORS settings
CORS_ENABLED=true
CORS_ORIGINS=*  # In production, specify allowed origins
CORS_CREDENTIALS=true

# API Key authentication (optional)
API_KEY_ENABLED=false
API_KEY=your_secret_api_key_here

# =============================================================================
# INTEGRATIONS
# =============================================================================

# OpenAI (for comparison endpoint)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_MAX_TOKENS=100

# =============================================================================
# DATA STORAGE
# =============================================================================

# Feedback storage
FEEDBACK_ENABLED=true
FEEDBACK_PATH=/home/claude/data/feedback

# Cache settings
CACHE_ENABLED=false
CACHE_TYPE=memory  # Options: memory, redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_TTL=3600  # seconds

# =============================================================================
# PERFORMANCE
# =============================================================================

# Request timeout
REQUEST_TIMEOUT=30  # seconds

# Model inference
INFERENCE_BATCH_SIZE=32
INFERENCE_MAX_LENGTH=512

# Worker settings
WORKER_CLASS=uvicorn.workers.UvicornWorker
WORKER_CONNECTIONS=1000

# =============================================================================
# DEVELOPMENT
# =============================================================================

# Debug mode
DEBUG=false

# Reload on code changes
RELOAD=false

# Profiling
ENABLE_PROFILING=false

# =============================================================================
# TESTING
# =============================================================================

# Test mode
TEST_MODE=false
MOCK_MODEL=false

# =============================================================================
# NOTES
# =============================================================================
# 1. Copy this file to .env and update values
# 2. Never commit .env file to git
# 3. Use strong API keys in production
# 4. Adjust rate limits based on expected load
# 5. Enable Redis cache for better performance
# 6. Monitor logs for errors and performance issues
