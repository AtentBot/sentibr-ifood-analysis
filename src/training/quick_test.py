"""
Script de teste rÃ¡pido do pipeline de treinamento
Use este script para testar rapidamente se o pipeline estÃ¡ funcionando
antes de fazer o treinamento completo
"""

import torch
from pathlib import Path
import logging
import sys

# Adicionar o diretÃ³rio raiz ao path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.config import config
from src.training.train import BERTTrainer
from src.training.dataset import load_data_for_training, create_data_loaders

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def quick_test(n_samples: int = 100, n_epochs: int = 1):
    """
    Teste rÃ¡pido do pipeline de treinamento
    
    Args:
        n_samples: NÃºmero de samples para usar (default: 100)
        n_epochs: NÃºmero de Ã©pocas para treinar (default: 1)
    """
    logger.info("=" * 60)
    logger.info("ğŸ§ª TESTE RÃPIDO DO PIPELINE DE TREINAMENTO")
    logger.info("=" * 60)
    logger.info(f"Usando {n_samples} samples por split")
    logger.info(f"Treinando por {n_epochs} Ã©poca(s)")
    
    # Verificar se os dados existem
    if not config.training.train_data_path.exists():
        logger.error(f"âŒ Arquivo de treino nÃ£o encontrado: {config.training.train_data_path}")
        logger.info("\nğŸ’¡ Execute primeiro:")
        logger.info("   1. python src/data/quick_test_data.py (para dados de teste)")
        logger.info("   2. python src/data/split_dataset.py")
        return
    
    # Carregar dados
    logger.info("\nğŸ“Š Carregando dados...")
    data = load_data_for_training(
        train_path=str(config.training.train_data_path),
        val_path=str(config.training.val_data_path),
        test_path=str(config.training.test_data_path)
    )
    
    # Usar apenas subset dos dados
    data['train'] = data['train'].head(n_samples)
    data['val'] = data['val'].head(n_samples // 5)
    data['test'] = data['test'].head(n_samples // 5)
    
    logger.info(f"  Train: {len(data['train'])} samples")
    logger.info(f"  Val:   {len(data['val'])} samples")
    logger.info(f"  Test:  {len(data['test'])} samples")
    
    # Inicializar trainer com configuraÃ§Ãµes de teste
    logger.info("\nğŸ¤– Inicializando modelo...")
    trainer = BERTTrainer(
        model_name=config.model.model_name,
        num_labels=config.model.num_labels,
        learning_rate=2e-5,
        num_epochs=n_epochs,
        batch_size=8,  # Batch size menor para teste rÃ¡pido
        max_length=128,  # Max length menor para teste rÃ¡pido
        warmup_steps=0,
        weight_decay=0.01
    )
    
    # Inicializar modelo
    trainer.initialize_model()
    
    # Criar data loaders
    logger.info("\nğŸ“¦ Criando data loaders...")
    loaders = create_data_loaders(
        train_df=data['train'],
        val_df=data['val'],
        test_df=data['test'],
        tokenizer=trainer.tokenizer,
        max_length=trainer.max_length,
        batch_size=trainer.batch_size
    )
    
    # Inicializar optimizer (IMPORTANTE!)
    logger.info("\nâš™ï¸ Inicializando optimizer...")
    num_training_steps = len(loaders['train']) * n_epochs
    trainer.initialize_optimizer(num_training_steps)
    
    # Treinar
    logger.info("\nğŸš€ Iniciando treinamento de teste...")
    logger.info("(Este Ã© apenas um teste rÃ¡pido, nÃ£o salvaremos o modelo)")
    
    # Fazer um epoch de treino sem salvar
    train_loss, train_acc = trainer.train_epoch(loaders['train'], epoch=0)
    
    logger.info(f"\nâœ… Train Loss: {train_loss:.4f}")
    logger.info(f"âœ… Train Acc: {train_acc:.4f}")
    
    # Validar
    logger.info("\nğŸ” Validando...")
    val_metrics = trainer.evaluate(loaders['val'])
    
    logger.info(f"âœ… Val Loss: {val_metrics['loss']:.4f}")
    logger.info(f"âœ… Val Acc: {val_metrics['accuracy']:.4f}")
    logger.info(f"âœ… Val F1: {val_metrics['f1']:.4f}")
    
    # Testar
    logger.info("\nğŸ§ª Testando...")
    test_metrics = trainer.evaluate(loaders['test'])
    
    logger.info(f"âœ… Test Loss: {test_metrics['loss']:.4f}")
    logger.info(f"âœ… Test Acc: {test_metrics['accuracy']:.4f}")
    logger.info(f"âœ… Test F1: {test_metrics['f1']:.4f}")
    
    logger.info("\n" + "=" * 60)
    logger.info("âœ… TESTE CONCLUÃDO COM SUCESSO!")
    logger.info("=" * 60)
    logger.info("\nğŸ’¡ O pipeline estÃ¡ funcionando corretamente!")
    logger.info("   Agora vocÃª pode executar o treinamento completo:")
    logger.info("   python src/training/train.py")
    
    # Verificar GPU
    if torch.cuda.is_available():
        logger.info(f"\nğŸ‰ GPU detectada: {torch.cuda.get_device_name(0)}")
        logger.info(f"   MemÃ³ria disponÃ­vel: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        logger.info("\nâš ï¸  Rodando em CPU (o treinamento completo serÃ¡ lento)")
        logger.info("   Considere usar Google Colab ou AWS para GPU")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Teste rÃ¡pido do pipeline de treinamento')
    parser.add_argument('--samples', type=int, default=100, help='NÃºmero de samples para usar')
    parser.add_argument('--epochs', type=int, default=1, help='NÃºmero de Ã©pocas para treinar')
    
    args = parser.parse_args()
    
    quick_test(n_samples=args.samples, n_epochs=args.epochs)
