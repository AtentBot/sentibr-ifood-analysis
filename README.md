# ğŸ” SentiBR - Sistema Inteligente de AnÃ¡lise de Sentimento para Reviews do iFood

<div align="center">

![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![BERT](https://img.shields.io/badge/BERT-Portuguese-orange.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

**AnÃ¡lise de Sentimento de Classe Mundial com BERT, FastAPI, Streamlit e MLOps**

[Demo](#-demo) â€¢ [Features](#-features) â€¢ [Quickstart](#-quickstart) â€¢ [Arquitetura](#-arquitetura) â€¢ [DocumentaÃ§Ã£o](#-documentaÃ§Ã£o)

</div>

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#-sobre-o-projeto)
- [Features Principais](#-features-principais)
- [Arquitetura](#-arquitetura)
- [Tech Stack](#-tech-stack)
- [Quickstart (3 comandos)](#-quickstart-3-comandos)
- [InstalaÃ§Ã£o Detalhada](#-instalaÃ§Ã£o-detalhada)
- [Uso](#-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Treinamento do Modelo](#-treinamento-do-modelo)
- [API Documentation](#-api-documentation)
- [Monitoramento](#-monitoramento)
- [Testes](#-testes)
- [Deployment](#-deployment)
- [DecisÃµes TÃ©cnicas](#-decisÃµes-tÃ©cnicas)
- [Roadmap](#-roadmap)
- [Contribuindo](#-contribuindo)
- [LicenÃ§a](#-licenÃ§a)

---

## ğŸ¯ Sobre o Projeto

**SentiBR** Ã© uma plataforma completa de anÃ¡lise de sentimento para reviews de restaurantes do iFood, construÃ­da com as melhores prÃ¡ticas de MLOps e Data Science. O projeto demonstra um ciclo completo de ML/DL, desde a experimentaÃ§Ã£o atÃ© a prototipagem para produÃ§Ã£o.

### ğŸŒŸ Diferenciais

- âœ… **Aspect-Based Sentiment Analysis**: AnÃ¡lise de sentimento por aspecto (comida, entrega, atendimento, preÃ§o)
- âœ… **ComparaÃ§Ã£o BERT vs GPT**: Trade-off entre latÃªncia, custo e qualidade
- âœ… **Observabilidade Completa**: Prometheus + Grafana + Logging estruturado
- âœ… **Data Drift Detection**: Monitoramento de distribuiÃ§Ã£o de dados
- âœ… **LLM-as-a-Judge**: GPT-4 avalia qualidade das prediÃ§Ãµes
- âœ… **Explicabilidade**: LIME/SHAP para interpretar decisÃµes
- âœ… **Continuous Learning**: Feedback loop para melhoria contÃ­nua
- âœ… **Production-Ready**: Docker, testes, CI/CD, documentaÃ§Ã£o completa

---

## ğŸš€ Features Principais

### ğŸ¤– Machine Learning
- Fine-tuning de BERT portuguÃªs para classificaÃ§Ã£o de sentimento
- Suporte a anÃ¡lise multi-aspecto
- Explicabilidade com LIME/SHAP
- Hyperparameter tuning com Optuna
- MLflow para tracking de experimentos

### ğŸŒ API REST
- FastAPI com validaÃ§Ã£o Pydantic
- Endpoints assÃ­ncronos
- Rate limiting
- Health checks
- Swagger UI customizado
- ComparaÃ§Ã£o BERT vs GPT-4o-mini

### ğŸ¨ Frontend Interativo
- Interface Streamlit responsiva
- AnÃ¡lise em tempo real
- Dashboard de mÃ©tricas
- Interface de feedback
- VisualizaÃ§Ãµes interativas

### ğŸ“Š Observabilidade
- Prometheus metrics
- Grafana dashboards
- Logging estruturado (JSON)
- Alertas customizados
- Data drift detection

### ğŸ³ Infrastructure
- Docker Compose para orquestraÃ§Ã£o
- Ngrok para acesso pÃºblico
- CI/CD ready
- Testes automatizados

---

## ğŸ—ï¸ Arquitetura

```mermaid
graph TB
    User[ğŸ‘¤ UsuÃ¡rio] --> Frontend[ğŸ¨ Streamlit Frontend]
    Frontend --> API[âš¡ FastAPI]
    API --> Cache[ğŸ’¾ Redis Cache]
    API --> BERT[ğŸ¤– BERT Model]
    API --> GPT[ğŸ§  GPT-4o-mini]
    API --> Prometheus[ğŸ“Š Prometheus]
    Prometheus --> Grafana[ğŸ“ˆ Grafana]
    API --> Logs[ğŸ“ Structured Logs]
    Feedback[ğŸ’¬ Feedback Loop] --> Training[ğŸ”„ Continuous Training]
    Training --> BERT
```

---

## ğŸ› ï¸ Tech Stack

### Core ML/DL
- **PyTorch** - Deep Learning framework
- **Transformers (Hugging Face)** - BERT implementation
- **scikit-learn** - ML utilities

### MLOps
- **MLflow** - Experiment tracking
- **Optuna** - Hyperparameter optimization
- **DVC** - Data versioning (opcional)
- **Great Expectations** - Data validation

### Backend
- **FastAPI** - Modern API framework
- **Uvicorn** - ASGI server
- **Pydantic** - Data validation
- **Redis** - Caching layer

### Frontend
- **Streamlit** - Interactive UI
- **Plotly** - Visualizations

### Monitoring
- **Prometheus** - Metrics collection
- **Grafana** - Visualization
- **Loguru** - Structured logging

### LLM
- **OpenAI API** - GPT-4o-mini for evaluation

### Infrastructure
- **Docker** - Containerization
- **Docker Compose** - Orchestration
- **Ngrok** - Public access

---

## âš¡ Quickstart (3 comandos)

```bash
# 1. Clone e setup
git clone <repo-url>
cd sentibr-ifood-analysis
cp .env.example .env  # Edite com suas keys

# 2. Build e start
docker-compose up -d

# 3. Acesse
# Frontend: http://localhost:8501
# API: http://localhost:8000/docs
# Grafana: http://localhost:3000
```

---

## ğŸ“¦ InstalaÃ§Ã£o Detalhada

### PrÃ©-requisitos
- Python 3.10+
- Docker & Docker Compose
- 8GB RAM mÃ­nimo
- GPU (opcional, acelera treinamento)

### Setup Local

```bash
# 1. Clone o repositÃ³rio
git clone <repo-url>
cd sentibr-ifood-analysis

# 2. Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Instale dependÃªncias
pip install -r requirements.txt

# 4. Configure variÃ¡veis de ambiente
cp .env.example .env
# Edite .env com suas configuraÃ§Ãµes (OpenAI API key, etc.)

# 5. Download do modelo prÃ©-treinado (se disponÃ­vel)
# Ou execute o treinamento (veja seÃ§Ã£o de Treinamento)
```

---

## ğŸ’» Uso

### 1. Treinar o Modelo

```bash
# Execute o script de treinamento
python src/training/train.py --config configs/train_config.yaml

# Com hyperparameter tuning
python src/training/hyperparameter_tuning.py --trials 20
```

### 2. Iniciar a API

```bash
# Local
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Docker
docker-compose up api
```

### 3. Iniciar o Frontend

```bash
# Local
streamlit run frontend/app.py

# Docker
docker-compose up frontend
```

### 4. Testar a API

```bash
# Health check
curl http://localhost:8000/api/v1/health

# PrediÃ§Ã£o simples
curl -X POST http://localhost:8000/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "A comida estava deliciosa mas a entrega demorou muito!"}'

# Resposta esperada:
{
  "sentiment": "misto",
  "confidence": 0.87,
  "aspects": {
    "comida": {"sentiment": "positivo", "confidence": 0.95},
    "entrega": {"sentiment": "negativo", "confidence": 0.88}
  },
  "latency_ms": 45
}

# ComparaÃ§Ã£o BERT vs GPT
curl -X POST http://localhost:8000/api/v1/predict/compare \
  -H "Content-Type: application/json" \
  -d '{"text": "ExperiÃªncia incrÃ­vel!"}'
```

---

## ğŸ“ Estrutura do Projeto

```
sentibr-ifood-analysis/
â”‚
â”œâ”€â”€ ğŸ“ data/                      # Dados do projeto
â”‚   â”œâ”€â”€ raw/                      # Dados brutos
â”‚   â”œâ”€â”€ processed/                # Dados processados
â”‚   â””â”€â”€ dvc/                      # Versionamento DVC
â”‚
â”œâ”€â”€ ğŸ“ models/                    # Modelos treinados
â”‚   â”œâ”€â”€ bert_finetuned/           # BERT fine-tuned
â”‚   â”œâ”€â”€ experiments/              # Experimentos MLflow
â”‚   â””â”€â”€ model_registry/           # Registro de versÃµes
â”‚
â”œâ”€â”€ ğŸ“ src/                       # CÃ³digo fonte
â”‚   â”œâ”€â”€ training/                 # Pipeline de treinamento
â”‚   â”‚   â”œâ”€â”€ train.py             # Script principal
â”‚   â”‚   â”œâ”€â”€ evaluate.py          # AvaliaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py     # ETL
â”‚   â”‚   â””â”€â”€ config.py            # ConfiguraÃ§Ãµes
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                      # API REST
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”‚   â”œâ”€â”€ models.py            # Pydantic models
â”‚   â”‚   â”œâ”€â”€ inference.py         # LÃ³gica de prediÃ§Ã£o
â”‚   â”‚   â””â”€â”€ middleware.py        # Middleware
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/               # Observabilidade
â”‚   â”‚   â”œâ”€â”€ metrics.py           # Prometheus metrics
â”‚   â”‚   â”œâ”€â”€ drift_detector.py    # Drift detection
â”‚   â”‚   â””â”€â”€ logger.py            # Logging config
â”‚   â”‚
â”‚   â””â”€â”€ evaluation/               # Framework de avaliaÃ§Ã£o
â”‚       â”œâ”€â”€ eval_suite.py        # Suite de mÃ©tricas
â”‚       â”œâ”€â”€ llm_judge.py         # LLM evaluation
â”‚       â””â”€â”€ explainer.py         # LIME/SHAP
â”‚
â”œâ”€â”€ ğŸ“ frontend/                  # Streamlit app
â”‚   â”œâ”€â”€ app.py                   # App principal
â”‚   â”œâ”€â”€ pages/                   # Multi-page app
â”‚   â”œâ”€â”€ components/              # Componentes
â”‚   â””â”€â”€ utils/                   # Utilidades
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb             # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ 02_experiments.ipynb     # Experimentos
â”‚   â””â”€â”€ 03_bert_vs_gpt.ipynb     # ComparaÃ§Ãµes
â”‚
â”œâ”€â”€ ğŸ“ docker/                    # Docker configs
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.frontend
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ ğŸ“ monitoring/                # Monitoring configs
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ dashboards/
â”‚
â”œâ”€â”€ ğŸ“ tests/                     # Testes
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ load/
â”‚
â”œâ”€â”€ ğŸ“ scripts/                   # Scripts auxiliares
â”‚   â”œâ”€â”€ expose.sh                # Ngrok
â”‚   â””â”€â”€ train.sh                 # Training helper
â”‚
â”œâ”€â”€ requirements.txt              # DependÃªncias Python
â”œâ”€â”€ .env.example                 # VariÃ¡veis de ambiente
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                    # Este arquivo
```

---

## ğŸ§  Treinamento do Modelo

### Dataset

Utilizamos reviews de restaurantes brasileiros com as seguintes caracterÃ­sticas:
- **Tamanho**: ~50.000 reviews
- **Classes**: Positivo, Negativo, Neutro
- **Aspectos**: Comida, Entrega, Atendimento, PreÃ§o
- **Idioma**: PortuguÃªs brasileiro

### Processo de Treinamento

1. **PrÃ©-processamento**
   - Limpeza de texto
   - TokenizaÃ§Ã£o com BERT tokenizer
   - Augmentation (opcional)

2. **Fine-tuning**
   - Modelo base: `neuralmind/bert-base-portuguese-cased`
   - Otimizador: AdamW
   - Learning rate: 2e-5
   - Batch size: 16
   - Epochs: 3-5

3. **AvaliaÃ§Ã£o**
   - MÃ©tricas: F1-score, Precision, Recall
   - Confusion Matrix
   - AnÃ¡lise de erros

### Reproduzir Treinamento

```bash
# 1. Preparar dados
python src/data/prepare_dataset.py

# 2. Treinar modelo
python src/training/train.py

# 3. Avaliar
python src/training/evaluate.py --model_path models/bert_finetuned

# 4. Visualizar no MLflow
mlflow ui
# Acesse: http://localhost:5000
```

---

## ğŸ“š API Documentation

A documentaÃ§Ã£o completa da API estÃ¡ disponÃ­vel em:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Principais Endpoints

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| POST | `/api/v1/predict` | PrediÃ§Ã£o Ãºnica |
| POST | `/api/v1/predict/batch` | PrediÃ§Ã£o em lote |
| POST | `/api/v1/predict/compare` | BERT vs GPT |
| GET | `/api/v1/health` | Health check |
| GET | `/api/v1/models/info` | Info do modelo |
| POST | `/api/v1/feedback` | Enviar feedback |
| POST | `/api/v1/explain` | Explicabilidade |
| GET | `/api/v1/metrics` | Prometheus metrics |

---

## ğŸ“Š Monitoramento

### Prometheus Metrics

Acesse: http://localhost:9090

MÃ©tricas disponÃ­veis:
- `api_requests_total` - Total de requisiÃ§Ãµes
- `api_request_duration_seconds` - LatÃªncia
- `prediction_confidence_score` - ConfianÃ§a mÃ©dia
- `drift_score` - Score de drift

### Grafana Dashboards

Acesse: http://localhost:3000 (admin/admin)

Dashboards:
1. **API Performance** - LatÃªncia, throughput, erros
2. **Model Performance** - DistribuiÃ§Ã£o, confianÃ§a, drift
3. **Business Metrics** - Sentimentos por categoria

### Data Drift Detection

```bash
# Check drift manualmente
python src/monitoring/drift_detector.py --baseline data/processed/baseline.csv

# API endpoint
curl http://localhost:8000/api/v1/drift/check
```

---

## ğŸ§ª Testes

```bash
# Todos os testes
pytest

# Com coverage
pytest --cov=src --cov-report=html

# Testes especÃ­ficos
pytest tests/unit/test_inference.py
pytest tests/integration/

# Load tests
locust -f tests/load/locustfile.py
```

---

## ğŸš€ Deployment

### Docker

```bash
# Build
docker-compose build

# Start all services
docker-compose up -d

# Logs
docker-compose logs -f api

# Stop
docker-compose down
```

### Ngrok (Acesso PÃºblico)

```bash
# 1. Instale ngrok: https://ngrok.com/download

# 2. Exponha API
ngrok http 8000

# 3. Exponha Frontend
ngrok http 8501

# As URLs pÃºblicas serÃ£o geradas automaticamente
```

### Cloud Deployment (Opcional)

Para deploy em produÃ§Ã£o, considere:
- **AWS**: ECS/EKS + ALB
- **GCP**: Cloud Run / GKE
- **Azure**: Container Apps
- **Heroku/Railway**: Deployment simples

---

## ğŸ¤” DecisÃµes TÃ©cnicas

### Por que BERT?

- âœ… SOTA para NLP em portuguÃªs
- âœ… Modelo compacto (~110M parÃ¢metros)
- âœ… LatÃªncia baixa (<100ms)
- âœ… Fine-tuning eficiente
- âœ… Interpretabilidade razoÃ¡vel

### Por que FastAPI?

- âœ… Performance excelente
- âœ… Async native
- âœ… ValidaÃ§Ã£o automÃ¡tica (Pydantic)
- âœ… Swagger UI built-in
- âœ… Type hints

### Por que Streamlit?

- âœ… Desenvolvimento rÃ¡pido
- âœ… Interface limpa
- âœ… IntegraÃ§Ã£o com plotly
- âœ… Multi-page apps
- âœ… Deploy simples

### BERT vs GPT-4o-mini

| MÃ©trica | BERT | GPT-4o-mini |
|---------|------|-------------|
| LatÃªncia | ~45ms | ~1200ms |
| Custo/1000 req | $0 | ~$0.10 |
| F1-Score | 0.89 | 0.92 |
| Explicabilidade | Alta | MÃ©dia |
| **RecomendaÃ§Ã£o** | ProduÃ§Ã£o | Casos crÃ­ticos |

---

## ğŸ—ºï¸ Roadmap

### âœ… VersÃ£o 1.0 (Atual)
- [x] Fine-tuning BERT
- [x] API REST completa
- [x] Frontend Streamlit
- [x] Monitoramento bÃ¡sico
- [x] Docker deployment

### ğŸ”„ VersÃ£o 1.1 (PrÃ³ximo)
- [ ] Aspect-based analysis completo
- [ ] A/B testing framework
- [ ] Continuous training pipeline
- [ ] Multi-model ensemble

### ğŸš€ VersÃ£o 2.0 (Futuro)
- [ ] Deploy em Kubernetes
- [ ] API GraphQL
- [ ] Mobile app
- [ ] Suporte multi-idioma
- [ ] Real-time streaming

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido com â¤ï¸ para demonstrar excelÃªncia em Data Science e MLOps.

---

## ğŸ“ Contato

- ğŸ“§ Email: contato@douglasbraga.com
- ğŸ’¼ LinkedIn: [linkedin](https://www.linkedin.com/in/dgbraga/)


---

<div align="center">

**â­ Se este projeto foi Ãºtil, considere dar uma estrela!**

</div>
